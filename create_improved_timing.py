#!/usr/bin/env python3
"""
ê°œì„ ëœ íƒ€ì´ë° JSON ìƒì„±ê¸°
- MP3 íŒŒì¼ ê²½ë¡œ
- ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
- ì‹œê°„ë³„ ì´ë¯¸ì§€ ë§¤ì¹­
- ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ê°€ëŠ¥í•œ êµ¬ì¡°
"""

import os
import json
import glob
from typing import Dict, List

def create_improved_timing_json():
    """ê°œì„ ëœ íƒ€ì´ë° JSON êµ¬ì¡° ìƒì„±"""
    
    # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
    base_dir = "output/kor-chn/kor-chn"
    timing_file = os.path.join(base_dir, "timing", "kor-chn_conversation.json")
    audio_file = os.path.join(base_dir, "mp3", "kor-chn_conversation.mp3")
    image_dir = os.path.join(base_dir, "conversation")
    
    # ê¸°ì¡´ íƒ€ì´ë° íŒŒì¼ ë¡œë“œ
    if os.path.exists(timing_file):
        with open(timing_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
    else:
        print(f"âŒ íƒ€ì´ë° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {timing_file}")
        return
    
    # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    screen1_images = sorted(glob.glob(os.path.join(image_dir, "*_screen1.png")))
    screen2_images = sorted(glob.glob(os.path.join(image_dir, "*_screen2.png")))
    
    print(f"ğŸ“ Screen1 ì´ë¯¸ì§€: {len(screen1_images)}ê°œ")
    print(f"ğŸ“ Screen2 ì´ë¯¸ì§€: {len(screen2_images)}ê°œ")
    
    # ê°œì„ ëœ íƒ€ì´ë° êµ¬ì¡° ìƒì„±
    improved_timing = {
        "project_info": {
            "name": "kor-chn",
            "type": "conversation",
            "total_duration": existing_data.get("total_duration", 0),
            "created_at": "2024-01-01T00:00:00Z"
        },
        "audio": {
            "file_path": audio_file,
            "duration": existing_data.get("total_duration", 0),
            "format": "mp3",
            "sample_rate": 44100
        },
        "video_segments": []
    }
    
    # ê° ì¥ë©´ë³„ë¡œ ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
    scenes = existing_data.get("scenes", [])
    
    for i, scene in enumerate(scenes):
        sequence = scene.get("sequence", str(i+1))
        timings = scene.get("timings", {})
        
        # Screen1 ì„¸ê·¸ë¨¼íŠ¸
        if "screen1" in timings and i < len(screen1_images):
            screen1_timing = timings["screen1"]
            start_time = screen1_timing.get("start", 0) / 1000.0  # msë¥¼ ì´ˆë¡œ ë³€í™˜
            end_time = screen1_timing.get("end", 0) / 1000.0
            duration = end_time - start_time
            
            improved_timing["video_segments"].append({
                "segment_id": f"scene_{sequence}_screen1",
                "sequence": int(sequence),
                "screen_type": "screen1",
                "start_time": round(start_time, 2),
                "end_time": round(end_time, 2),
                "duration": round(duration, 2),
                "image": {
                    "file_path": screen1_images[i],
                    "filename": os.path.basename(screen1_images[i]),
                    "exists": os.path.exists(screen1_images[i])
                },
                "audio": {
                    "start_time": round(start_time, 2),
                    "end_time": round(end_time, 2),
                    "duration": round(duration, 2)
                }
            })
        
        # Screen2 ì„¸ê·¸ë¨¼íŠ¸
        if "screen2" in timings and i < len(screen2_images):
            screen2_timing = timings["screen2"]
            start_time = screen2_timing.get("start", 0) / 1000.0  # msë¥¼ ì´ˆë¡œ ë³€í™˜
            end_time = screen2_timing.get("end", 0) / 1000.0
            duration = end_time - start_time
            
            improved_timing["video_segments"].append({
                "segment_id": f"scene_{sequence}_screen2",
                "sequence": int(sequence),
                "screen_type": "screen2",
                "start_time": round(start_time, 2),
                "end_time": round(end_time, 2),
                "duration": round(duration, 2),
                "image": {
                    "file_path": screen2_images[i],
                    "filename": os.path.basename(screen2_images[i]),
                    "exists": os.path.exists(screen2_images[i])
                },
                "audio": {
                    "start_time": round(start_time, 2),
                    "end_time": round(end_time, 2),
                    "duration": round(duration, 2)
                }
            })
    
    # FFmpeg concat íŒŒì¼ ìƒì„±ìš© ì •ë³´ ì¶”ê°€
    improved_timing["ffmpeg_concat"] = {
        "concat_file": os.path.join(base_dir, "video", "concat_list.txt"),
        "output_file": os.path.join(base_dir, "video", "kor-chn_conversation_improved.mp4"),
        "segments": []
    }
    
    # FFmpeg concat ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ìƒì„±
    for segment in improved_timing["video_segments"]:
        if segment["image"]["exists"]:
            improved_timing["ffmpeg_concat"]["segments"].append({
                "file": f"file '{segment['image']['file_path']}'",
                "duration": segment["duration"],
                "start_time": segment["start_time"],
                "end_time": segment["end_time"]
            })
    
    # ê°œì„ ëœ íƒ€ì´ë° íŒŒì¼ ì €ì¥
    improved_timing_file = os.path.join(base_dir, "timing", "kor-chn_conversation_improved.json")
    os.makedirs(os.path.dirname(improved_timing_file), exist_ok=True)
    
    with open(improved_timing_file, 'w', encoding='utf-8') as f:
        json.dump(improved_timing, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê°œì„ ëœ íƒ€ì´ë° JSON ìƒì„± ì™„ë£Œ: {improved_timing_file}")
    print(f"ğŸ“Š ì´ {len(improved_timing['video_segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
    
    # FFmpeg concat íŒŒì¼ ìƒì„±
    concat_file = improved_timing["ffmpeg_concat"]["concat_file"]
    os.makedirs(os.path.dirname(concat_file), exist_ok=True)
    
    with open(concat_file, 'w', encoding='utf-8') as f:
        for segment in improved_timing["ffmpeg_concat"]["segments"]:
            f.write(f"{segment['file']}\n")
            f.write(f"duration {segment['duration']}\n")
    
    print(f"âœ… FFmpeg concat íŒŒì¼ ìƒì„± ì™„ë£Œ: {concat_file}")
    
    return improved_timing_file

if __name__ == "__main__":
    create_improved_timing_json()
