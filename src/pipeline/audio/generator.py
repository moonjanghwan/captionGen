"""
Google Cloud Text-to-Speech APIë¥¼ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ ìƒì„±ê¸°

SSMLì„ MP3ë¡œ ë³€í™˜í•˜ê³  ì •í™•í•œ íƒ€ì´ë° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import os
import json
import tempfile
import subprocess
from typing import Dict, List, Any, Optional, Tuple
from google.cloud import texttospeech
from google.cloud.texttospeech_v1 import AudioConfig, AudioEncoding
import wave
import struct
import io

from .ssml_builder import SSMLBuilder


class AudioGenerator:
    """ì˜¤ë””ì˜¤ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, credentials_path: Optional[str] = None):
        """
        ì˜¤ë””ì˜¤ ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            credentials_path: Google Cloud ì¸ì¦ íŒŒì¼ ê²½ë¡œ
        """
        self.ssml_builder = SSMLBuilder()
        self.client = None
        self._initialize_client(credentials_path)
        
        # ì˜¤ë””ì˜¤ ì„¤ì •
        self.audio_config = AudioConfig(
            audio_encoding=AudioEncoding.MP3,
            sample_rate_hertz=22050,
            effects_profile_id=["headphone-class-device"]
        )
    
    def _initialize_client(self, credentials_path: Optional[str] = None):
        """Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            if credentials_path and os.path.exists(credentials_path):
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
            
            self.client = texttospeech.TextToSpeechClient()
            print("âœ… Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            
        except Exception as e:
            print(f"âš ï¸ Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ”§ ë¡œì»¬ TTS ë˜ëŠ” ë‹¤ë¥¸ ì„œë¹„ìŠ¤ ì‚¬ìš©ì„ ê³ ë ¤í•˜ì„¸ìš”")
            self.client = None
    
    def _synthesize_text_segment(self, text: str, voice_name: str, language_code: str, output_path: str) -> bool:
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì¡°ê°ì„ ìŒì„±ìœ¼ë¡œ í•©ì„±í•©ë‹ˆë‹¤."""
        if not self.client or not text or not voice_name or not language_code:
            print(f"TTS í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜, í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. Voice: {voice_name}, Lang: {language_code}, Text: {text[:20]}...")
            return False
        try:
            synthesis_input = texttospeech.SynthesisInput(text=text)
            voice_params = texttospeech.VoiceSelectionParams(
                language_code=language_code,
                name=voice_name
            )
            
            response = self.client.synthesize_speech(
                input=synthesis_input,
                voice=voice_params,
                audio_config=self.audio_config
            )
            
            with open(output_path, "wb") as out:
                out.write(response.audio_content)
            
            print(f"âœ… ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±: {os.path.basename(output_path)}")
            return True

        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì‹¤íŒ¨ ({voice_name}): {e}")
            return False
    
    def generate_audio_from_manifest(self, manifest_data: Dict[str, Any], 
                                   output_dir: str, script_type: str = "conversation") -> Tuple[bool, str]:
        """
        Manifestì—ì„œ ì¥ë©´ë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ê³  ë³‘í•©í•˜ì—¬ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë§Œë“­ë‹ˆë‹¤.
        """
        try:
            project_name = manifest_data.get("project_name", "untitled_project")
            identifier = manifest_data.get("identifier", project_name)
            scenes = manifest_data.get("scenes", [])

            # 1. í™”ì ì„¤ì • ë¡œë“œ
            voice_configs = self._load_voice_configs(project_name, identifier)
            if not voice_configs:
                print("í™”ì ì„¤ì •ì´ ì—†ì–´ ì˜¤ë””ì˜¤ ìƒì„±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False, ""

            # 2. ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_dir = tempfile.mkdtemp(prefix="audio_segments_")
            segment_paths = []

            # 3. ì¥ë©´ë³„, íŒŒíŠ¸ë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            for scene in scenes:
                scene_segments = self._generate_segments_for_scene(scene, voice_configs, temp_dir)
                if not scene_segments:
                    print(f"ì¥ë©´ {scene.get('sequence')} ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨. ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    return False, ""
                segment_paths.extend(scene_segments)

            # 4. ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ë³‘í•©
            os.makedirs(output_dir, exist_ok=True)
            english_script_type = {"íšŒí™”": "conversation", "ëŒ€í™”": "conversation", "ì¸íŠ¸ë¡œ": "intro", "ì—”ë”©": "ending"}.get(script_type, script_type)
            final_audio_path = os.path.join(output_dir, f"{identifier}_{english_script_type}.mp3")

            success = self.merge_audio_segments(segment_paths, final_audio_path)

            # 5. ì„ì‹œ íŒŒì¼ ì •ë¦¬ (í•„ìš” ì‹œ)
            # for path in segment_paths: os.remove(path)
            # os.rmdir(temp_dir)

            if success:
                print(f"âœ… ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì™„ë£Œ: {final_audio_path}")
                return True, final_audio_path
            else:
                print("âŒ ìµœì¢… ì˜¤ë””ì˜¤ íŒŒì¼ ë³‘í•© ì‹¤íŒ¨")
                return False, ""

        except Exception as e:
            import traceback
            print(f"âŒ Manifest ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            print(traceback.format_exc())
            return False, ""

    def _generate_segments_for_scene(self, scene: Dict[str, Any], voice_configs: Dict[str, Any], temp_dir: str) -> List[str]:
        """í•œ ì¥ë©´ì„ êµ¬ì„±í•˜ëŠ” ëª¨ë“  ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸(ìŒì„±+ë¬´ìŒ)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        scene_type = scene.get("type")
        sequence = scene.get("sequence", scene.get("id", "unknown"))
        segment_paths = []

        if scene_type == "conversation":
            # 1. ì›ì–´ ìŠ¤í¬ë¦½íŠ¸
            native_script = scene.get("native_script", "")
            if native_script:
                voice_info = voice_configs.get("native", {})
                output_path = os.path.join(temp_dir, f"scene_{sequence}_native.mp3")
                success = self._synthesize_text_segment(native_script, voice_info.get("name"), voice_info.get("language"), output_path)
                if not success: return []
                segment_paths.append(output_path)

            # 2. 1ì´ˆ ë¬´ìŒ
            silence_path = self._create_silence_segment(1, os.path.join(temp_dir, f"scene_{sequence}_silence_1.mp3"))
            if not silence_path: return []
            segment_paths.append(silence_path)

            # 3. í•™ìŠµì–´ ìŠ¤í¬ë¦½íŠ¸ (4íšŒ ë°˜ë³µ)
            learning_script = scene.get("learning_script", "")
            if learning_script:
                for i in range(1, 5):
                    voice_info = voice_configs.get(f"learner_{i}", {})
                    output_path = os.path.join(temp_dir, f"scene_{sequence}_learner_{i}.mp3")
                    success = self._synthesize_text_segment(learning_script, voice_info.get("name"), voice_info.get("language"), output_path)
                    if not success: return []
                    segment_paths.append(output_path)

                    # ë§ˆì§€ë§‰ í•™ìŠµì–´ ë’¤ì—ëŠ” ë¬´ìŒ ì—†ìŒ
                    if i < 4:
                        silence_path = self._create_silence_segment(1, os.path.join(temp_dir, f"scene_{sequence}_silence_learner_{i}.mp3"))
                        if not silence_path: return []
                        segment_paths.append(silence_path)
            
            return segment_paths

        elif scene_type in ["intro", "ending"]:
            script_text = scene.get("full_script") or scene.get("script_text", "")
            if script_text:
                voice_info = voice_configs.get("native", {})
                output_path = os.path.join(temp_dir, f"scene_{sequence}_{scene_type}.mp3")
                success = self._synthesize_text_segment(script_text, voice_info.get("name"), voice_info.get("language"), output_path)
                if not success: return []
                segment_paths.append(output_path)
            return segment_paths

        else:
            print(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¥ë©´ íƒ€ì…: {scene_type}")
            return []

    def _create_silence_segment(self, duration_seconds: int, output_path: str) -> Optional[str]:
        """ì§€ì •ëœ ê¸¸ì´ì˜ ë¬´ìŒ MP3 íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ìŒ ì˜¤ë””ì˜¤ ìƒì„± (macOS í˜¸í™˜ì„±ì„ ìœ„í•´ í°ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)
            command = f'ffmpeg -f lavfi -i anullsrc=r=22050:cl=mono -t {duration_seconds} -q:a 9 -acodec libmp3lame "{output_path}"'
            
            # FFmpeg ì‹¤í–‰
            result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
            
            print(f"âœ… ë¬´ìŒ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±: {os.path.basename(output_path)}")
            return output_path
        except subprocess.CalledProcessError as e:
            print(f"âŒ ë¬´ìŒ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì‹¤íŒ¨ (FFmpeg ì˜¤ë¥˜): {e.stderr}")
            return None
        except Exception as e:
            print(f"âŒ ë¬´ìŒ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return None

    def _load_voice_configs(self, project_name: str, identifier: str) -> Optional[Dict[str, Any]]:
        """í™”ì ì„¤ì • íŒŒì¼ (speaker.json)ì„ ë¡œë“œí•˜ê³  SSMLBuilderì— ë§ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        try:
            # config.py ë˜ëŠ” ë‹¤ë¥¸ ì„¤ì • ê´€ë¦¬ìì—ì„œ OUTPUT_PATHë¥¼ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ì ˆëŒ€ ê²½ë¡œë¥¼ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
            speaker_config_path = os.path.join("output", project_name, identifier, f"{identifier}_speaker.json")

            if not os.path.exists(speaker_config_path):
                print(f"âš ï¸ í™”ì ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {speaker_config_path}. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return None

            with open(speaker_config_path, 'r', encoding='utf-8') as f:
                settings = json.load(f)
            
            print(f"âœ… í™”ì ì„¤ì •ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤: {speaker_config_path}")

            # SSMLBuilderê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            voice_configs = {
                "native": {
                    "name": settings.get("native_speaker"),
                    "language": self._extract_lang_code(settings.get("native_speaker"))
                }
            }
            
            learner_speakers = settings.get("learner_speakers", [])
            for i, speaker_name in enumerate(learner_speakers):
                voice_configs[f"learner_{i+1}"] = {
                    "name": speaker_name,
                    "language": self._extract_lang_code(speaker_name)
                }
            
            return voice_configs

        except Exception as e:
            print(f"âŒ í™”ì ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return None

    def _extract_lang_code(self, voice_name: str) -> str:
        """ìŒì„± ì´ë¦„ì—ì„œ ì–¸ì–´ ì½”ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ì˜ˆ: ko-KR-Standard-A -> ko-KR)."""
        if not voice_name:
            return ""
        parts = voice_name.split('-')
        if len(parts) >= 2:
            return f"{parts[0]}-{parts[1]}"
        return ""
    
    def extract_timing_info(self, ssml_content: str, audio_path: str) -> Dict[str, Any]:
        """
        SSMLê³¼ ì˜¤ë””ì˜¤ì—ì„œ íƒ€ì´ë° ì •ë³´ ì¶”ì¶œ
        
        Args:
            ssml_content: SSML ë‚´ìš©
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: íƒ€ì´ë° ì •ë³´
        """
        # SSMLì—ì„œ mark íƒœê·¸ ì •ë³´ ì¶”ì¶œ
        marks = self.ssml_builder.get_mark_timings(ssml_content)
        
        # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° (ëŒ€ëµì  ì¶”ì •)
        audio_duration = self._estimate_audio_duration(audio_path)
        
        # íƒ€ì´ë° ì •ë³´ êµ¬ì„±
        timing_info = {
            "audio_file": audio_path,
            "total_duration": audio_duration,
            "marks": marks,
            "scenes": self._analyze_scene_timings(marks, audio_duration)
        }
        
        return timing_info
    
    def _estimate_audio_duration(self, audio_path: str) -> float:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ ì¶”ì • (ì´ˆ ë‹¨ìœ„)"""
        try:
            # MP3 íŒŒì¼ ê¸¸ì´ë¥¼ ì •í™•íˆ ê³„ì‚°í•˜ëŠ” ê²ƒì€ ë³µì¡í•˜ë¯€ë¡œ
            # íŒŒì¼ í¬ê¸°ì™€ ë¹„íŠ¸ë ˆì´íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
            file_size = os.path.getsize(audio_path)
            
            # MP3 ë¹„íŠ¸ë ˆì´íŠ¸ (kbps) - ê¸°ë³¸ê°’ 128kbps
            bitrate = 128 * 1000  # bits per second
            
            # íŒŒì¼ í¬ê¸° (bits) / ë¹„íŠ¸ë ˆì´íŠ¸ = ì´ˆ
            duration = (file_size * 8) / bitrate
            
            return round(duration, 2)
            
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¶”ì • ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _analyze_scene_timings(self, marks: List[Dict[str, Any]], 
                              total_duration: float) -> List[Dict[str, Any]]:
        """ì¥ë©´ë³„ íƒ€ì´ë° ë¶„ì„"""
        scenes = []
        current_scene = None
        
        for mark in marks:
            mark_name = mark["name"]
            
            # ì¥ë©´ ë²ˆí˜¸ ì¶”ì¶œ
            if "scene_" in mark_name:
                parts = mark_name.split("_")
                if len(parts) >= 2:
                    scene_num = parts[1]
                    
                    if current_scene is None or current_scene["sequence"] != scene_num:
                        # ìƒˆ ì¥ë©´ ì‹œì‘
                        current_scene = {
                            "sequence": scene_num,
                            "type": "conversation",
                            "timings": {
                                "screen1": {"start": None, "end": None},
                                "screen2": {"start": None, "end": None}
                            }
                        }
                        scenes.append(current_scene)
                    
                    # íƒ€ì´ë° ì •ë³´ ì—…ë°ì´íŠ¸
                    if "screen1_start" in mark_name:
                        current_scene["timings"]["screen1"]["start"] = mark["position"]
                    elif "screen1_end" in mark_name:
                        current_scene["timings"]["screen1"]["end"] = mark["position"]
                    elif "screen2_start" in mark_name:
                        current_scene["timings"]["screen2"]["start"] = mark["position"]
                    elif "screen2_end" in mark_name:
                        current_scene["timings"]["screen2"]["end"] = mark["position"]
        
        return scenes
    
    def create_audio_segments(self, manifest_data: Dict[str, Any], 
                            output_dir: str) -> List[str]:
        """
        ê° ì¥ë©´ë³„ë¡œ ê°œë³„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
        
        Args:
            manifest_data: Manifest ë°ì´í„°
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            
        Returns:
            List[str]: ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        segments = []
        scenes = manifest_data.get("scenes", [])
        
        for scene in scenes:
            scene_type = scene.get("type", "")
            scene_id = scene.get("id", "")
            
            if scene_type == "conversation":
                # conversation íƒ€ì…ì€ ë³„ë„ SSML ìƒì„±
                ssml_content = self.ssml_builder.build_conversation_ssml(scene)
                
                # ê°œë³„ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±
                segment_path = os.path.join(output_dir, f"{scene_id}_audio.mp3")
                if self.generate_audio_from_ssml(ssml_content, segment_path):
                    segments.append(segment_path)
            
            elif scene_type in ["intro", "ending"]:
                # intro/ending íƒ€ì…
                ssml_content = self.ssml_builder.build_intro_ending_ssml(scene)
                
                segment_path = os.path.join(output_dir, f"{scene_id}_audio.mp3")
                if self.generate_audio_from_ssml(ssml_content, segment_path):
                    segments.append(segment_path)
            
            elif scene_type == "dialogue":
                # dialogue íƒ€ì…
                ssml_content = self.ssml_builder.build_dialogue_ssml(scene)
                
                segment_path = os.path.join(output_dir, f"{scene_id}_audio.mp3")
                if self.generate_audio_from_ssml(ssml_content, segment_path):
                    segments.append(segment_path)
        
        return segments
    
    def merge_audio_segments(self, segment_paths: List[str], 
                           output_path: str) -> bool:
        """FFmpegë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•©ë‹ˆë‹¤."""
        if not segment_paths:
            print("ë³‘í•©í•  ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        try:
            # FFmpegëŠ” íŒŒì¼ ê²½ë¡œì— ê³µë°±ì´ ìˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê²½ë¡œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
            # ë˜í•œ, ìœˆë„ìš°ì™€ macOS/Linuxì˜ ê²½ë¡œ êµ¬ë¶„ì ì°¨ì´ë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” Pythonì˜ os.path.abspathë¥¼ ì‚¬ìš©í•˜ì—¬ ì ˆëŒ€ ê²½ë¡œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
            
            # merge list íŒŒì¼ ìƒì„±
            list_content = ""
            for path in segment_paths:
                # ê²½ë¡œì˜ ë°±ìŠ¬ë˜ì‹œë¥¼ ìŠ¬ë˜ì‹œë¡œ ë³€ê²½ (ffmpeg í˜¸í™˜ì„±)
                safe_path = os.path.abspath(path).replace('\\', '/')
                list_content += f"file '{safe_path}'\n"
            
            # ì„ì‹œ íŒŒì¼ì— ë¦¬ìŠ¤íŠ¸ ì‘ì„±
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix=".txt", encoding='utf-8') as tmp_list_file:
                tmp_list_file.write(list_content)
                merge_list_path = tmp_list_file.name

            print(f"âœ… ë³‘í•© ë¦¬ìŠ¤íŠ¸ ìƒì„±: {merge_list_path}")

            # FFmpeg ë³‘í•© ëª…ë ¹ ì‹¤í–‰
            command = f'ffmpeg -f concat -safe 0 -i "{merge_list_path}" -c copy "{output_path}" -y'
            print(f"ì‹¤í–‰í•  FFmpeg ëª…ë ¹: {command}")

            result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
            
            print(f"âœ… ì˜¤ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_path}")
            os.remove(merge_list_path) # ì„ì‹œ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ
            return True

        except subprocess.CalledProcessError as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨ (FFmpeg ì˜¤ë¥˜): {e.stderr}")
            if os.path.exists(merge_list_path):
                os.remove(merge_list_path)
            return False
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ë³‘í•© ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            if 'merge_list_path' in locals() and os.path.exists(merge_list_path):
                os.remove(merge_list_path)
            return False
    
    def get_voice_list(self) -> List[Dict[str, str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡ ë°˜í™˜"""
        if not self.client:
            return []
        
        try:
            voices = self.client.list_voices()
            voice_list = []
            
            for voice in voices.voices:
                voice_list.append({
                    "name": voice.name,
                    "language_code": voice.language_codes[0] if voice.language_codes else "",
                    "gender": voice.ssml_gender.name if voice.ssml_gender else ""
                })
            
            return voice_list
            
        except Exception as e:
            print(f"âš ï¸ ìŒì„± ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def test_tts_connection(self) -> bool:
        """TTS ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.client:
            return False
        
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
            synthesis_input = texttospeech.SynthesisInput(text="í…ŒìŠ¤íŠ¸")
            voice_params = texttospeech.VoiceSelectionParams(language_code="ko-KR")
            response = self.client.synthesize_speech(
                input=synthesis_input,
                voice=voice_params,
                audio_config=self.audio_config
            )
            
            return len(response.audio_content) > 0
            
        except Exception as e:
            print(f"TTS ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
