import os
import subprocess
import tempfile
import json
from typing import List, Dict, Optional
import ffmpeg

class FFmpegRenderer:
    def __init__(self):
        self._check_ffmpeg_availability()

    def _check_ffmpeg_availability(self):
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        except FileNotFoundError:
            raise FileNotFoundError("FFmpeg is not installed or not in the system's PATH.")
    
    def _load_timing_data(self, project_name: str, identifier: str, video_type: str) -> Optional[Dict]:
        """ê¹”ë”í•œ íƒ€ì´ë° ë°ì´í„° ë¡œë“œ"""
        try:
            # ìŠ¤í¬ë¦½íŠ¸ íƒ€ì…ì„ ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜
            script_type_mapping = {
                "intro": "intro",
                "ending": "ending", 
                "conversation": "conversation"
            }
            english_script_type = script_type_mapping.get(video_type, video_type)
            
            # ê¹”ë”í•œ íƒ€ì´ë° íŒŒì¼ ê²½ë¡œ ìš°ì„  ì‹œë„
            clean_timing_path = os.path.join("output", project_name, identifier, "timing", f"{identifier}_{english_script_type}_clean.json")
            legacy_timing_path = os.path.join("output", project_name, identifier, f"{identifier}_{english_script_type}.json")
            
            # ê¹”ë”í•œ íƒ€ì´ë° íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            if os.path.exists(clean_timing_path):
                with open(clean_timing_path, 'r', encoding='utf-8') as f:
                    timing_data = json.load(f)
                print(f"âœ… ê¹”ë”í•œ íƒ€ì´ë° ë°ì´í„° ë¡œë“œ: {clean_timing_path}")
                return timing_data
            # ê¸°ì¡´ íƒ€ì´ë° íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            elif os.path.exists(legacy_timing_path):
                with open(legacy_timing_path, 'r', encoding='utf-8') as f:
                    timing_data = json.load(f)
                print(f"âœ… ê¸°ì¡´ íƒ€ì´ë° ë°ì´í„° ë¡œë“œ: {legacy_timing_path}")
                return timing_data
            else:
                print(f"âš ï¸ íƒ€ì´ë° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {clean_timing_path} ë˜ëŠ” {legacy_timing_path}")
                return None
        except Exception as e:
            print(f"âŒ íƒ€ì´ë° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def render_scene_video(self, audio_path: str, subtitle_frames: List[Dict], output_path: str, resolution: str, default_background: str):
        width, height = map(int, resolution.split('x'))
        
        total_duration = sum(f['duration'] for f in subtitle_frames)
        if total_duration == 0:
            print("Warning: Total duration is zero. Cannot render video.")
            return

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as concat_file:
            for frame in subtitle_frames:
                concat_file.write(f"file '{os.path.abspath(frame['output_path'])}'\n")
                concat_file.write(f"duration {frame['duration']}\n")
            # The last image needs to be specified again without duration
            if subtitle_frames:
                concat_file.write(f"file '{os.path.abspath(subtitle_frames[-1]['output_path'])}'\n")
            concat_list_path = concat_file.name

        try:
            background_input = ffmpeg.input(default_background, loop=1, t=total_duration).filter('scale', width, height)
            image_input = ffmpeg.input(concat_list_path, f='concat', safe=0, r='30')
            audio_input = ffmpeg.input(audio_path)

            video_stream = ffmpeg.overlay(background_input, image_input, x='(W-w)/2', y='(H-h)/2')

            (ffmpeg
                .output(video_stream, audio_input, output_path, vcodec='libx264', acodec='aac', pix_fmt='yuv420p', shortest=None)
                .run(overwrite_output=True, quiet=True))
        finally:
            if os.path.exists(concat_list_path):
                os.remove(concat_list_path)

    def merge_videos(self, video_paths: List[str], output_path: str):
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as concat_file:
            for path in video_paths:
                concat_file.write(f"file '{os.path.abspath(path)}'\n")
            concat_list_path = concat_file.name
        
        try:
            (ffmpeg
                .input(concat_list_path, f='concat', safe=0)
                .output(output_path, c='copy')
                .run(overwrite_output=True, quiet=True))
        finally:
            if os.path.exists(concat_list_path):
                os.remove(concat_list_path)

    def create_conversation_video(self, conversation_data: List[Dict], audio_path: str, 
                                 subtitle_dir: str, output_path: str, resolution: str, 
                                 background_path: str) -> bool:
        """
        íšŒí™” ë¹„ë””ì˜¤ ìƒì„± - ì œì‘ ì‚¬ì–‘ì„œì— ë”°ë¥¸ íƒ€ì´ë° ì ìš©
        """
        try:
            width, height = map(int, resolution.split('x'))
            
            # 1. ì‹¤ì œ ìƒì„±ëœ íšŒí™” ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
            import glob
            screen1_pattern = os.path.join(subtitle_dir, "kor-chn_*_screen1.png")
            screen2_pattern = os.path.join(subtitle_dir, "kor-chn_*_screen2.png")
            
            screen1_files = sorted(glob.glob(screen1_pattern))
            screen2_files = sorted(glob.glob(screen2_pattern))
            
            if not screen1_files and not screen2_files:
                print(f"âŒ íšŒí™” ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {subtitle_dir}")
                return False
            
            print(f"ğŸ“ íšŒí™” ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬ - Screen1: {len(screen1_files)}ê°œ, Screen2: {len(screen2_files)}ê°œ")
            
            # 2. ê¹”ë”í•œ íƒ€ì´ë° ì •ë³´ ë¡œë“œ ë° ìƒì„±
            timing_data = self._load_timing_data("kor-chn", "kor-chn", "conversation")
            video_segments = []
            
            if timing_data and 'segments' in timing_data:
                # ê¹”ë”í•œ íƒ€ì´ë° êµ¬ì¡° ì‚¬ìš©
                print(f"âœ… ê¹”ë”í•œ íƒ€ì´ë° êµ¬ì¡° ì‚¬ìš©: {len(timing_data['segments'])}ê°œ ì„¸ê·¸ë¨¼íŠ¸")
                
                for segment in timing_data['segments']:
                    image_file = segment.get('image_file')
                    duration = segment.get('duration', 1.0)
                    screen_type = segment.get('screen_type', 'unknown')
                    sequence = segment.get('sequence', 1)
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸
                    if os.path.exists(image_file):
                        video_segments.append({
                            'type': screen_type,
                            'image_path': image_file,
                            'start_time': segment.get('start_time', 0.0),
                            'duration': duration,
                            'sequence': sequence
                        })
                        print(f"  ğŸ“Š {screen_type} íƒ€ì´ë° ì‚¬ìš©: {os.path.basename(image_file)} - {duration}ì´ˆ")
                    else:
                        print(f"  âŒ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_file}")
            else:
                # ê¸°ë³¸ íƒ€ì´ë° ì‚¬ìš© (ê¸°ì¡´ ë°©ì‹)
                print(f"âš ï¸ ê¹”ë”í•œ íƒ€ì´ë° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íƒ€ì´ë°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                current_time = 0.0
                max_scenes = max(len(screen1_files), len(screen2_files))
                
                for i in range(max_scenes):
                    # Screen1 ì²˜ë¦¬
                    if i < len(screen1_files):
                        screen1_duration = 2.0  # ì›ì–´ ì¬ìƒ ì‹œê°„ (ê¸°ë³¸ê°’)
                        print(f"  âš ï¸ Screen1 ê¸°ë³¸ íƒ€ì´ë° ì‚¬ìš©: {os.path.basename(screen1_files[i])} - {screen1_duration}ì´ˆ")
                        
                        video_segments.append({
                            'type': 'screen1',
                            'image_path': screen1_files[i],
                            'start_time': current_time,
                            'duration': screen1_duration,
                            'sequence': i + 1
                        })
                        current_time += screen1_duration
                        
                        # ë¬´ìŒ 1ì´ˆ
                        current_time += 1.0
                    
                    # Screen2 ì²˜ë¦¬
                    if i < len(screen2_files):
                        screen2_duration = 4.0  # í•™ìŠµì–´ + ì½ê¸° ì¬ìƒ ì‹œê°„ (ê¸°ë³¸ê°’)
                        print(f"  âš ï¸ Screen2 ê¸°ë³¸ íƒ€ì´ë° ì‚¬ìš©: {os.path.basename(screen2_files[i])} - {screen2_duration}ì´ˆ")
                        
                        video_segments.append({
                            'type': 'screen2',
                            'image_path': screen2_files[i],
                            'start_time': current_time,
                            'duration': screen2_duration,
                            'sequence': i + 1
                        })
                        current_time += screen2_duration
                        
                        # ë¬´ìŒ 1ì´ˆ (ë§ˆì§€ë§‰ ì¥ë©´ ì œì™¸)
                        if i < max_scenes - 1:
                            current_time += 1.0
            
            if not video_segments:
                print("âŒ íšŒí™” ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 3. concat ë¦¬ìŠ¤íŠ¸ ìƒì„±
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as concat_file:
                for segment in video_segments:
                    if os.path.exists(segment['image_path']):
                        concat_file.write(f"file '{os.path.abspath(segment['image_path'])}'\n")
                        concat_file.write(f"duration {segment['duration']}\n")
                # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ë‹¤ì‹œ ì¶”ê°€ (duration ì—†ì´)
                if video_segments:
                    concat_file.write(f"file '{os.path.abspath(video_segments[-1]['image_path'])}'\n")
                concat_list_path = concat_file.name
            
            # 4. ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸
            has_audio = audio_path and os.path.exists(audio_path)
            if not has_audio:
                print(f"âŒ íšŒí™” ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
                return False
            
            # 5. ë¹„ë””ì˜¤ ë Œë”ë§ (ìë§‰ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©, ë°°ê²½ ì´ë¯¸ì§€ ë¶ˆí•„ìš”)
            print(f"ğŸ¬ ìë§‰ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìƒì„± (ë°°ê²½ ì´ë¯¸ì§€ ë¶ˆí•„ìš”)")
            image_input = ffmpeg.input(concat_list_path, f='concat', safe=0, r='30')
            audio_input = ffmpeg.input(audio_path)
            
            # ìë§‰ ì´ë¯¸ì§€ì— í•´ìƒë„ ì ìš©
            video_stream = image_input.filter('scale', width, height)
            
            (ffmpeg
                .output(video_stream, audio_input, output_path, vcodec='libx264', acodec='aac', pix_fmt='yuv420p', shortest=None)
                .run(overwrite_output=True, quiet=True))
            
            print(f"âœ… íšŒí™” ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ íšŒí™” ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ğŸ” ë””ë²„ê·¸ ì •ë³´:")
            print(f"  - conversation_data: {conversation_data}")
            print(f"  - audio_path: {audio_path}")
            print(f"  - subtitle_dir: {subtitle_dir}")
            print(f"  - output_path: {output_path}")
            print(f"  - resolution: {resolution}")
            print(f"  - background_path: {background_path}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            if 'concat_list_path' in locals() and os.path.exists(concat_list_path):
                os.remove(concat_list_path)

    def create_intro_ending_video(self, sentences: List[str], audio_path: str, 
                                 subtitle_dir: str, output_path: str, resolution: str,
                                 background_path: str, video_type: str = "intro") -> bool:
        """
        ì¸íŠ¸ë¡œ/ì—”ë”© ë¹„ë””ì˜¤ ìƒì„± - ë¬¸ì¥ë³„ ì´ë¯¸ì§€ë¥¼ íƒ€ì´ë°ì— ë§ì¶° ìƒì„±
        """
        try:
            width, height = map(int, resolution.split('x'))
            
            # 1. ì‹¤ì œ ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì°¾ê¸°
            video_segments = []
            current_time = 0.0
            
            # ì‹¤ì œ íŒŒì¼ëª… íŒ¨í„´ìœ¼ë¡œ ì´ë¯¸ì§€ ì°¾ê¸°
            import glob
            image_pattern = os.path.join(subtitle_dir, f"kor-chn_{video_type}_*.png")
            image_files = sorted(glob.glob(image_pattern))
            
            if not image_files:
                print(f"âŒ {video_type} ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_pattern}")
                return False
            
            print(f"ğŸ“ {video_type} ì´ë¯¸ì§€ íŒŒì¼ {len(image_files)}ê°œ ë°œê²¬")
            
            # íƒ€ì´ë° ì •ë³´ ë¡œë“œ ì‹œë„
            timing_data = self._load_timing_data(project_name, identifier, video_type)
            
            for i, image_path in enumerate(image_files):
                # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                if timing_data and i < len(timing_data.get('segments', [])):
                    segment = timing_data['segments'][i]
                    sentence_duration = segment.get('duration', 3.0)
                    print(f"  ğŸ“Š íƒ€ì´ë° ì‚¬ìš©: {os.path.basename(image_path)} - {sentence_duration}ì´ˆ")
                else:
                    sentence_duration = 3.0
                    print(f"  âš ï¸ ê¸°ë³¸ íƒ€ì´ë° ì‚¬ìš©: {os.path.basename(image_path)} - {sentence_duration}ì´ˆ")
                
                video_segments.append({
                    'image_path': image_path,
                    'start_time': current_time,
                    'duration': sentence_duration,
                    'sentence': f"{video_type} {i+1}"
                })
                current_time += sentence_duration
                
                # ë¬¸ì¥ê°„ ë¬´ìŒ 1ì´ˆ (ë§ˆì§€ë§‰ ë¬¸ì¥ ì œì™¸)
                if i < len(image_files) - 1:
                    current_time += 1.0
            
            if not video_segments:
                print(f"âŒ {video_type} ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 2. concat ë¦¬ìŠ¤íŠ¸ ìƒì„±
            with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as concat_file:
                for segment in video_segments:
                    concat_file.write(f"file '{os.path.abspath(segment['image_path'])}'\n")
                    concat_file.write(f"duration {segment['duration']}\n")
                # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ë‹¤ì‹œ ì¶”ê°€ (duration ì—†ì´)
                if video_segments:
                    concat_file.write(f"file '{os.path.abspath(video_segments[-1]['image_path'])}'\n")
                concat_list_path = concat_file.name
            
            # 3. ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸ (ì„ íƒì )
            has_audio = audio_path and os.path.exists(audio_path)
            if not has_audio:
                print(f"âš ï¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
            
            # 4. ë¹„ë””ì˜¤ ë Œë”ë§ (ìë§‰ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©, ë°°ê²½ ì´ë¯¸ì§€ ë¶ˆí•„ìš”)
            print(f"ğŸ¬ ìë§‰ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©í•˜ì—¬ {video_type} ë¹„ë””ì˜¤ ìƒì„± (ë°°ê²½ ì´ë¯¸ì§€ ë¶ˆí•„ìš”)")
            image_input = ffmpeg.input(concat_list_path, f='concat', safe=0, r='30')
            
            # ìë§‰ ì´ë¯¸ì§€ì— í•´ìƒë„ ì ìš©
            video_stream = image_input.filter('scale', width, height)
            
            if has_audio:
                audio_input = ffmpeg.input(audio_path)
                (ffmpeg
                    .output(video_stream, audio_input, output_path, vcodec='libx264', acodec='aac', pix_fmt='yuv420p', shortest=None)
                    .run(overwrite_output=True, quiet=True))
            else:
                (ffmpeg
                    .output(video_stream, output_path, vcodec='libx264', pix_fmt='yuv420p')
                    .run(overwrite_output=True, quiet=True))
            
            print(f"âœ… {video_type} ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ {video_type} ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            if 'concat_list_path' in locals() and os.path.exists(concat_list_path):
                os.remove(concat_list_path)

    def create_final_merged_video(self, intro_path: str, conversation_path: str, 
                                 ending_path: str, output_path: str) -> bool:
        """
        ìµœì¢… ë¹„ë””ì˜¤ ë³‘í•© - ì¸íŠ¸ë¡œ + íšŒí™” + ì—”ë”©
        """
        try:
            video_paths = []
            
            # ì¡´ì¬í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ë§Œ ì¶”ê°€
            if intro_path and os.path.exists(intro_path):
                video_paths.append(intro_path)
            if conversation_path and os.path.exists(conversation_path):
                video_paths.append(conversation_path)
            if ending_path and os.path.exists(ending_path):
                video_paths.append(ending_path)
            
            if not video_paths:
                print("âŒ ë³‘í•©í•  ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ë¹„ë””ì˜¤ ë³‘í•©
            self.merge_videos(video_paths, output_path)
            print(f"âœ… ìµœì¢… ë¹„ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ìµœì¢… ë¹„ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨: {e}")
            return False