상세 비디오 제작 로직 구현 계획이 문서는 video_production_pipeline_v2를 기반으로, 회화, 인트로/엔딩, 대화 비디오의 고유한 요구사항을 만족시키기 위한 상세한 데이터 구조와 렌더링 로직을 정의합니다.1. 회화 비디오 (Conversation Video) 제작 로직각 대화 행을 원어 학습 화면과 학습어 집중 연습 화면으로 분리하여 렌더링합니다.1.1. 데이터 구조 확장 (timeline_manifest.json)conversation 타입의 dialogue 객체에 reading (읽기) 필드와 연습을 위한 practiceSpeakers 수를 추가합니다.{
  "id": "kor-chn-lesson1_conversation_01",
  "type": "conversation",
  "bg": "assets/bg_scene1.jpg",
  "practiceSpeakers": 4, // 학습어 반복 횟수
  "dialogue": [
    {
      "seq": 1,
      "speaker": "A",
      "native": "안녕하세요",
      "learning": "你好",
      "reading": "Nǐ hǎo"
    }
    // ... more dialogues
  ]
}
1.2. 오디오 및 타임스탬프 생성 (segments.json)하나의 대화 행에 대해 다음과 같이 세그먼트를 생성합니다.원어 오디오: 원어 텍스트로 TTS 요청 (<mark name="native_1_start"/>...<mark name="native_1_end"/>)무음 1: 1초학습어 오디오 1~4: practiceSpeakers 수만큼 학습어 텍스트로 TTS 요청. 각 요청은 별개의 화자 목소리(voice)를 사용하고, 고유 마크를 가집니다. (예: <mark name="learn_1_1_start"/>)각 오디오 세그먼트 사이에 1초 무음을 삽입합니다._conversation_segments.json 결과 예시:{
  "segments": [
    // --- 행 1 ---
    // 화면 1: 원어
    { "id": "native_1", "text": "안녕하세요", "start_ms": 0, "end_ms": 1200 },
    { "id": "silence_1_1", "type": "silence", "start_ms": 1200, "end_ms": 2200 },
    // 화면 2: 학습어 반복
    { "id": "learn_1_1", "text": "你好", "start_ms": 2200, "end_ms": 3100, "voice": "cmn-CN-Wavenet-A" },
    { "id": "silence_1_2", "type": "silence", "start_ms": 3100, "end_ms": 4100 },
    { "id": "learn_1_2", "text": "你好", "start_ms": 4100, "end_ms": 5000, "voice": "cmn-CN-Wavenet-B" },
    { "id": "silence_1_3", "type": "silence", "start_ms": 5000, "end_ms": 6000 },
    { "id": "learn_1_3", "text": "你好", "start_ms": 6000, "end_ms": 6900, "voice": "cmn-CN-Wavenet-C" },
    { "id": "silence_1_4", "type": "silence", "start_ms": 6900, "end_ms": 7900 },
    { "id": "learn_1_4", "text": "你好", "start_ms": 7900, "end_ms": 8800, "voice": "cmn-CN-Wavenet-D" }
  ]
}
1.3. 렌더링 로직 (FFmpeg)segments.json을 기반으로 각 행마다 2개의 비디오 클립을 생성 후 합칩니다.클립 1 (원어 화면):표시 시간: native_1의 start_ms ~ end_ms표시 내용: 순번 (seq), 원어 텍스트 (native)클립 2 (학습어 화면):표시 시간: learn_1_1의 start_ms ~ learn_1_4의 end_ms표시 내용: 순번 (seq), 원어 (native), 학습어 (learning), 읽기 (reading)2. 인트로/엔딩 비디오 (Intro/Ending) 제작 로직스크립트를 지능적으로 분할하고 스타일을 적용하여 동적인 자막을 생성합니다.2.1. 데이터 구조 확장 (timeline_manifest.json)text 필드에 Markdown과 유사한 스타일링 속성을 지원합니다.{
  "id": "kor-chn-lesson1_intro_01",
  "type": "intro",
  "bg": "assets/bg_intro.jpg",
  "v_offset": 800, // 자막 마지막 줄의 기준 Y 좌표
  "text": [
    "오늘 배울 표현은 바로 <color:yellow>**'안녕하세요'**</color> 입니다.",
    "정말 유용한 표현이니 꼭 외워두세요!"
  ]
}
2.2. 스마트 자막 분리 및 위치 계산 로직문장 분리: 렌더링 전, 각 문장의 픽셀 길이를 계산합니다. 화면 너비를 초과하면 공백을 기준으로 문장을 분할하여 최대 3줄의 배열로 만듭니다.위치 계산:v_offset은 항상 마지막 줄의 기준선이 됩니다.line_y = v_offset - ((total_lines - 1) - current_line_index) * line_height1줄 자막: y = v_offset2줄 자막: 1번째 줄 y = v_offset - line_height, 2번째 줄 y = v_offset3줄 자막: 1번째 줄 y = v_offset - (2 * line_height), 2번째 줄 y = v_offset - line_height, 3번째 줄 y = v_offset2.3. 렌더링 로직 (ASS 자막 활용)스타일 파싱: <color:yellow>**...**</color>와 같은 md 속성을 파싱하여 ASS(Advanced SubStation Alpha) 자막 형식의 스타일 태그({\c&HYELLOW&}{\b1}...\b0\c&HFFFFFF&})로 변환합니다.하드섭: FFmpeg를 사용하여 오디오와 함께 이 스타일이 적용된 ASS 자막을 비디오에 직접 렌더링(하드섭)합니다.3. 대화 비디오 (Dialogue Video) 제작 로직여러 화자가 등장하는 상황극을 연출합니다.3.1. 데이터 구조 확장 (timeline_manifest.json)화자별 텍스트 위치와 반복 정보를 정의합니다.{
  "id": "kor-chn-lesson1_dialogue_01",
  "type": "dialogue",
  "bg": "assets/bg_cafe.jpg",
  "speakers": [ // 화자별 고정 위치 정의
    {"name": "Narrator", "position": [100, 100]},
    {"name": "Speaker1", "position": [200, 300]},
    {"name": "Speaker2", "position": [200, 500]}
  ],
  "script": [
    {
      "speaker": "Narrator",
      "text": "카페에서 두 사람이 만납니다.",
      "repeat": 1 // 내레이션은 1번만
    },
    {
      "speaker": "Speaker1",
      "text": "안녕하세요",
      "repeat": 2 // 화자 대사는 2번 반복
    },
    {
      "speaker": "Speaker2",
      "text": "네, 안녕하세요",
      "repeat": 2
    }
  ]
}
3.2. 오디오 및 타임스탬프 생성script의 각 항목에 대해 repeat 수만큼 오디오를 생성하고, 그 사이에 1초 무음을 삽입합니다.이 과정으로 생성된 segments.json은 각 오디오의 정확한 시작/종료 시간을 가집니다.3.3. 렌더링 로직script의 한 항목(예: Speaker1의 "안녕하세요")에 해당하는 모든 오디오 세그먼트를 찾습니다.자막 표시 시간:start_ms: 첫 번째 반복 오디오(repeat: 1)의 시작 시간end_ms: 마지막 반복 오디오(repeat: 2)의 종료 시간자막 위치: speakers 배열에서 현재 화자의 position 값을 찾아 해당 좌표에 텍스트를 렌더링합니다.내레이터: speaker가 "Narrator"인 경우, 지정된 내레이터 위치에 텍스트를 표시합니다. 내레이터 항목이 없으면 해당 부분은 건너뜁니다.