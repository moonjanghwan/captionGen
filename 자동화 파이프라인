### **타입별 영상 제작을 위한 표준화된 자동화 파이프라인**

이 시스템은 비디오의 구조와 내용을 정의하는 **Manifest 파일**을 기반으로, 오디오 생성, 자막 이미지 생성, 최종 비디오 렌더링 과정을 완전히 자동화하는 것을 목표로 합니다.

#### **[1단계] 비디오 구조 설계 (Timeline Manifest 작성)**

자동화의 시작은 만들고자 하는 비디오의 전체 흐름과 내용을 기계가 읽을 수 있는 형식으로 정의하는 것입니다. 이 역할을 하는 것이 바로 `timeline_manifest.json` 파일입니다. 이 파일은 전체 파이프라인의 \*\*청사진(Blueprint)\*\*이자 \*\*단일 정보 소스(Single Source of Truth)\*\*가 됩니다.

**프로세스:**

1.  **`timeline_manifest.json` 파일 생성:** 프로젝트의 루트에 이 파일을 생성합니다.
2.  **전체 구조 정의:** `scenes`라는 배열(Array)을 만들어, 비디오에 포함될 각 장면을 순서대로 객체(Object) 형태로 추가합니다. 자동화 스크립트는 이 `scenes` 배열을 순서대로 읽어 비디오를 조립합니다.
3.  **장면(Scene) 타입별 속성 정의:** 각 장면 객체에는 `id`(고유 식별자)와 `type`을 필수로 지정합니다. `type` (`intro`, `conversation`, `dialogue`, `ending`)에 따라 후속 자동화 단계(자막 생성, 오디오 구성 등)가 어떤 로직을 실행할지 결정됩니다.

**`timeline_manifest.json` 예시:**

```json
{
  "project_name": "Effective Communication Ep.1",
  "resolution": "1920x1080",
  "default_background": "assets/bg_main.mp4",
  "scenes": [
    {
      "id": "intro_01",
      "type": "intro",
      "full_script": "안녕하세요! 효과적인 커뮤니케이션 시리즈에 오신 것을 환영합니다."
    },
    {
      "id": "dialogue_01",
      "type": "dialogue",
      "script": [
        { "speaker": "A", "text": "어제 보낸 파일 확인하셨나요?" },
        { "speaker": "B", "text": "네, 지금 막 확인했습니다. 몇 가지 질문이 있어요." }
      ]
    },
    {
      "id": "conversation_01",
      "type": "conversation",
      "sequence": 1,
      "native_script": "Let's get started.",
      "learning_script": "시작해 봅시다.",
      "reading_script": "Si-jak-hae bop-si-da."
    },
    {
      "id": "ending_01",
      "type": "ending",
      "full_script": "시청해주셔서 감사합니다. 구독과 좋아요를 잊지 마세요!"
    }
  ]
}
```

이처럼 Manifest 파일을 작성하면, 비디오의 순서를 바꾸거나 대사를 수정하는 등의 모든 변경 작업을 **오직 이 파일 하나만 수정**하는 것으로 관리할 수 있게 됩니다.

-----

#### **[2단계] 오디오 생성 및 타임스탬프 추출 (SSML 활용)**

Manifest의 각 Scene을 순회하며 필요한 모든 오디오와 타이밍 데이터를 생성합니다.

**프로세스:**

1.  `timeline_manifest.json`의 `scenes` 배열을 반복합니다.
2.  각 scene의 `type`에 따라 다른 SSML을 구성하여 TTS API에 요청합니다.
      * **`intro`, `ending`, `dialogue`:** 문장 단위로 `<mark>` 태그를 삽입합니다.
      * **`conversation`:** 원어, 학습어(4회 반복) 음성을 각각 생성하고, 화자 사이에 1초 무음을 프로그래밍 방식으로 추가할 오디오 리스트를 준비합니다.
3.  결과로 마스터 오디오 파일(`_master.mp3`)과 각 `<mark>`의 정확한 시간이 기록된 타이밍 파일(`_segments.json`)을 저장합니다.

-----

#### **[3단계] 타입별 자막 PNG 시퀀스 생성**

이 단계가 시스템의 핵심입니다. Manifest의 `type`을 기준으로 각기 다른 자막 생성 로직을 호출합니다.

**프로세스:**

1.  다시 `scenes` 배열을 반복합니다.
2.  `scene.type`에 따라 분기 처리합니다.
      * **`type: "intro"` 또는 `type: "ending"`:**
          * `full_script`를 가져옵니다.
          * `_segments.json`의 문장 타이밍에 맞춰, '스마트 줄바꿈' 로직을 적용한 자막 이미지를 생성합니다.
          * 결과물: `intro_01_seg_0.png`, `intro_01_seg_1.png`...
      * **`type: "conversation"`:**
          * 요구사항에 명시된 2개의 화면을 별도로 렌더링합니다.
          * **화면 1:** 원어 음성 길이에 맞춰 "순번 + 원어" 텍스트가 포함된 `conversation_01_screen1.png`를 생성합니다.
          * **화면 2:** 4명의 학습어 음성 전체 길이에 맞춰 "순번 + 원어 + 학습어 + 읽기" 텍스트가 포함된 `conversation_01_screen2.png`를 생성합니다.
      * **`type: "dialogue"`:**
          * `script` 배열을 가져옵니다.
          * `_segments.json`의 화자별 대사 타이밍에 맞춰, 지정된 위치에 화자 이름과 대사가 포함된 자막 이미지를 생성합니다.
          * 결과물: `dialogue_01_seg_0.png` (A), `dialogue_01_seg_1.png` (B) ...

-----

#### **[4단계] 최종 비디오 렌더링 (FFmpeg)**

모든 재료(배경, 오디오, 자막 PNG)를 합쳐 최종 비디오를 완성합니다.

**프로세스:**

1.  자동화 스크립트는 Manifest 파일과 지금까지 생성된 모든 리소스(오디오, 타이밍 데이터, PNG 시퀀스)를 읽어 들입니다.
2.  FFmpeg 스크립트를 동적으로 생성합니다. 이 스크립트는 `_segments.json`의 정확한 타임스탬프를 사용하여, 적절한 시간에 각 자막 PNG 이미지를 `overlay` 필터로 추가하고, 최종 오디오 파일을 합칩니다.
3.  생성된 FFmpeg 명령을 실행하여 최종 비디오 파일(`.mp4`)을 출력합니다.
